Start training Indian_Pines_Corrected dataset
Epoch 1, MSE Loss: 0.05614647906846725
Epoch 2, MSE Loss: 0.026004275229687873
Epoch 3, MSE Loss: 0.022953813629081617
Epoch 4, MSE Loss: 0.021382850766755068
Epoch 5, MSE Loss: 0.020316373800429013
Epoch 6, MSE Loss: 0.019529813293081063
Epoch 7, MSE Loss: 0.018791861731845598
Epoch 8, MSE Loss: 0.018226114955659095
Epoch 9, MSE Loss: 0.017544273533500156
Epoch 10, MSE Loss: 0.01703588952238743
Epoch 11, MSE Loss: 0.01660414531540412
Epoch 12, MSE Loss: 0.016220608332122747
Epoch 13, MSE Loss: 0.01587119033273596
Epoch 14, MSE Loss: 0.01567748882736151
Epoch 15, MSE Loss: 0.015264104660600424
Epoch 16, MSE Loss: 0.014969024704052852
Epoch 17, MSE Loss: 0.014757537453507002
Epoch 18, MSE Loss: 0.014498612634264506
Epoch 19, MSE Loss: 0.014275989694377551
Epoch 20, MSE Loss: 0.014081799628642888
Epoch 21, MSE Loss: 0.013898459101239076
Epoch 22, MSE Loss: 0.013689125548475064
Epoch 23, MSE Loss: 0.013514950626458112
Epoch 24, MSE Loss: 0.013302576715269914
Epoch 25, MSE Loss: 0.013145218196396644
Epoch 26, MSE Loss: 0.012991686737021575
Epoch 27, MSE Loss: 0.012808281875287111
Epoch 28, MSE Loss: 0.01264192147180438
Epoch 29, MSE Loss: 0.012941019519303853
Epoch 30, MSE Loss: 0.012263829888632664
Epoch 31, MSE Loss: 0.012180485712507596
Epoch 32, MSE Loss: 0.012047135974638737
Epoch 33, MSE Loss: 0.011925425810309557
Epoch 34, MSE Loss: 0.011773178757956394
Epoch 35, MSE Loss: 0.011655743539046783
Epoch 36, MSE Loss: 0.011507895353894968
Epoch 37, MSE Loss: 0.01139237489981147
Epoch 38, MSE Loss: 0.011253708449120705
Epoch 39, MSE Loss: 0.011137758630972642
Epoch 40, MSE Loss: 0.011027944668267783
Epoch 41, MSE Loss: 0.010890764791805011
Epoch 42, MSE Loss: 0.010779912613618832
Epoch 43, MSE Loss: 0.010664194035702027
Epoch 44, MSE Loss: 0.010566868878041322
Epoch 45, MSE Loss: 0.010446039800747082
Epoch 46, MSE Loss: 0.010343181814711827
Epoch 47, MSE Loss: 0.010257028463081672
Epoch 48, MSE Loss: 0.010146170046467047
Epoch 49, MSE Loss: 0.010059647853844441
Epoch 50, MSE Loss: 0.009976861296364894
Epoch 51, MSE Loss: 0.009878521631830013
Epoch 52, MSE Loss: 0.009795424360781908
Epoch 53, MSE Loss: 0.009712675334169314
Epoch 54, MSE Loss: 0.009641926327290443
Epoch 55, MSE Loss: 0.009559905245327032
Epoch 56, MSE Loss: 0.009483894177067739
Epoch 57, MSE Loss: 0.009407580013458545
Epoch 58, MSE Loss: 0.00934193778783083
Epoch 59, MSE Loss: 0.009282448860601736
Epoch 60, MSE Loss: 0.009210089753166987
Epoch 61, MSE Loss: 0.009150624024466826
Epoch 62, MSE Loss: 0.009093005095536892
Epoch 63, MSE Loss: 0.009033889415172431
Epoch 64, MSE Loss: 0.008977899058507039
Epoch 65, MSE Loss: 0.00891882163973955
Epoch 66, MSE Loss: 0.008873381461375035
Epoch 67, MSE Loss: 0.008824185830755876
Epoch 68, MSE Loss: 0.008779253896612388
Epoch 69, MSE Loss: 0.008728716541081667
Epoch 70, MSE Loss: 0.008686729166656732
Epoch 71, MSE Loss: 0.008646886265621736
Epoch 72, MSE Loss: 0.008604388815852312
Epoch 73, MSE Loss: 0.008571234018756793
Epoch 74, MSE Loss: 0.008531658520492223
Epoch 75, MSE Loss: 0.008495715067077142
Epoch 76, MSE Loss: 0.008464745680013529
Epoch 77, MSE Loss: 0.00843562548263715
Epoch 78, MSE Loss: 0.008403408689281116
Epoch 79, MSE Loss: 0.008375175979991371
Epoch 80, MSE Loss: 0.008351029661985544
Epoch 81, MSE Loss: 0.008324935709197933
Epoch 82, MSE Loss: 0.008302148352735317
Epoch 83, MSE Loss: 0.008281840706387392
Epoch 84, MSE Loss: 0.00826372553809331
Epoch 85, MSE Loss: 0.008245264313971767
Epoch 86, MSE Loss: 0.008229704254235212
Epoch 87, MSE Loss: 0.008212638881344062
Epoch 88, MSE Loss: 0.008198052011430264
Epoch 89, MSE Loss: 0.008186830295106539
Epoch 90, MSE Loss: 0.008172062000689598
Epoch 91, MSE Loss: 0.00816495224260367
Epoch 92, MSE Loss: 0.008154804286045524
Epoch 93, MSE Loss: 0.008150734997426088
Epoch 94, MSE Loss: 0.00814531377158486
Epoch 95, MSE Loss: 0.008138563645143922
Epoch 96, MSE Loss: 0.008133977845024605
Epoch 97, MSE Loss: 0.00813194765852621
Epoch 98, MSE Loss: 0.008132493872768603
Epoch 99, MSE Loss: 0.00812995558246397
Epoch 100, MSE Loss: 0.008129423451251708
Finish training Indian_Pines_Corrected dataset
Save checkpoint to ./experiments/models/checkpoints/MSTPlus/Indian_Pines_Corrected
finish all datasets

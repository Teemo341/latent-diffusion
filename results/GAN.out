Start training Indian_Pines_Corrected dataset
warmup epoches 1/3
Epoch [1/30], Step [203/407], d_loss_real: 0.4088, d_loss_fake: 0.3946
Epoch [1/30], Step [406/407], d_loss_real: 0.2255, d_loss_fake: 0.2197
warmup epoches 2/3
Epoch [2/30], Step [203/407], d_loss_real: 0.0105, d_loss_fake: 0.0111
Epoch [2/30], Step [406/407], d_loss_real: 0.0076, d_loss_fake: 0.0080
warmup epoches 3/3
Epoch [3/30], Step [203/407], d_loss_real: 0.0025, d_loss_fake: 0.0027
Epoch [3/30], Step [406/407], d_loss_real: 0.0021, d_loss_fake: 0.0022
Epoch [4/30], Step [203/407], d_loss_real: 0.3005, d_loss_fake: 0.2944, g_loss: 2.2428
Epoch [4/30], Step [406/407], d_loss_real: 0.4984, d_loss_fake: 0.4112, g_loss: 1.6844
Epoch [5/30], Step [203/407], d_loss_real: 0.6136, d_loss_fake: 0.4702, g_loss: 1.2203
Epoch [5/30], Step [406/407], d_loss_real: 0.6292, d_loss_fake: 0.4931, g_loss: 1.1673
Epoch [6/30], Step [203/407], d_loss_real: 0.6811, d_loss_fake: 0.5089, g_loss: 1.1087
Epoch [6/30], Step [406/407], d_loss_real: 0.6554, d_loss_fake: 0.5125, g_loss: 1.0959
Epoch [7/30], Step [203/407], d_loss_real: 0.2042, d_loss_fake: 0.1830, g_loss: 2.2835
Epoch [7/30], Step [406/407], d_loss_real: 0.1273, d_loss_fake: 0.1230, g_loss: 2.7273
Epoch [8/30], Step [203/407], d_loss_real: 0.0214, d_loss_fake: 0.0326, g_loss: 3.7574
Epoch [8/30], Step [406/407], d_loss_real: 0.0160, d_loss_fake: 0.0257, g_loss: 4.0170
Epoch [9/30], Step [203/407], d_loss_real: 0.0364, d_loss_fake: 0.0255, g_loss: 4.7439
Epoch [9/30], Step [406/407], d_loss_real: 0.2320, d_loss_fake: 0.1057, g_loss: 3.7824
Epoch [10/30], Step [203/407], d_loss_real: 0.5516, d_loss_fake: 0.3534, g_loss: 1.7709
Epoch [10/30], Step [406/407], d_loss_real: 0.5867, d_loss_fake: 0.3895, g_loss: 1.6462
Epoch [11/30], Step [203/407], d_loss_real: 0.6106, d_loss_fake: 0.4490, g_loss: 1.3153
Epoch [11/30], Step [406/407], d_loss_real: 0.6425, d_loss_fake: 0.4576, g_loss: 1.2761
Epoch [12/30], Step [203/407], d_loss_real: 0.5868, d_loss_fake: 0.4010, g_loss: 1.4558
Epoch [12/30], Step [406/407], d_loss_real: 0.6003, d_loss_fake: 0.4404, g_loss: 1.3094
Epoch [13/30], Step [203/407], d_loss_real: 0.5560, d_loss_fake: 0.4166, g_loss: 1.3866
Epoch [13/30], Step [406/407], d_loss_real: 0.4859, d_loss_fake: 0.3132, g_loss: 1.7095
Epoch [14/30], Step [203/407], d_loss_real: 0.4679, d_loss_fake: 0.3227, g_loss: 1.7271
Epoch [14/30], Step [406/407], d_loss_real: 0.5869, d_loss_fake: 0.4123, g_loss: 1.4576
Epoch [15/30], Step [203/407], d_loss_real: 0.5951, d_loss_fake: 0.5208, g_loss: 1.0927
Epoch [15/30], Step [406/407], d_loss_real: 0.6575, d_loss_fake: 0.5550, g_loss: 1.0524
Epoch [16/30], Step [203/407], d_loss_real: 0.7522, d_loss_fake: 0.6346, g_loss: 0.8435
Epoch [16/30], Step [406/407], d_loss_real: 0.7265, d_loss_fake: 0.6376, g_loss: 0.8360
Epoch [17/30], Step [203/407], d_loss_real: 0.6925, d_loss_fake: 0.6386, g_loss: 0.8337
Epoch [17/30], Step [406/407], d_loss_real: 0.6792, d_loss_fake: 0.6028, g_loss: 0.8859
Epoch [18/30], Step [203/407], d_loss_real: 0.6936, d_loss_fake: 0.6211, g_loss: 0.8671
Epoch [18/30], Step [406/407], d_loss_real: 0.6004, d_loss_fake: 0.5468, g_loss: 1.0031
Epoch [19/30], Step [203/407], d_loss_real: 0.1306, d_loss_fake: 0.1276, g_loss: 2.4358
Epoch [19/30], Step [406/407], d_loss_real: 0.0946, d_loss_fake: 0.0845, g_loss: 3.0696
Epoch [20/30], Step [203/407], d_loss_real: 0.0277, d_loss_fake: 0.0211, g_loss: 4.3830
Epoch [20/30], Step [406/407], d_loss_real: 0.0225, d_loss_fake: 0.0181, g_loss: 4.5345
Epoch [21/30], Step [203/407], d_loss_real: 0.0127, d_loss_fake: 0.0133, g_loss: 4.8140
Epoch [21/30], Step [406/407], d_loss_real: 0.0119, d_loss_fake: 0.0134, g_loss: 4.8141
Epoch [22/30], Step [203/407], d_loss_real: 0.0092, d_loss_fake: 0.0082, g_loss: 5.2992
Epoch [22/30], Step [406/407], d_loss_real: 0.0072, d_loss_fake: 0.0069, g_loss: 5.5379
Epoch [23/30], Step [203/407], d_loss_real: 0.0049, d_loss_fake: 0.0045, g_loss: 5.9960
Epoch [23/30], Step [406/407], d_loss_real: 0.0047, d_loss_fake: 0.0039, g_loss: 6.1814
Epoch [24/30], Step [203/407], d_loss_real: 0.0029, d_loss_fake: 0.0033, g_loss: 6.4685
Epoch [24/30], Step [406/407], d_loss_real: 0.0029, d_loss_fake: 0.0028, g_loss: 6.6469
Epoch [25/30], Step [203/407], d_loss_real: 0.0021, d_loss_fake: 0.0021, g_loss: 6.9663
Epoch [25/30], Step [406/407], d_loss_real: 0.0019, d_loss_fake: 0.0018, g_loss: 7.1578
Epoch [26/30], Step [203/407], d_loss_real: 0.0025, d_loss_fake: 0.0014, g_loss: 7.4645
Epoch [26/30], Step [406/407], d_loss_real: 0.0022, d_loss_fake: 0.0013, g_loss: 7.5500
Epoch [27/30], Step [203/407], d_loss_real: 0.0013, d_loss_fake: 0.0009, g_loss: 7.7798
Epoch [27/30], Step [406/407], d_loss_real: 0.0010, d_loss_fake: 0.0008, g_loss: 7.9234
Epoch [28/30], Step [203/407], d_loss_real: 0.0009, d_loss_fake: 0.0006, g_loss: 8.1644
Epoch [28/30], Step [406/407], d_loss_real: 0.0008, d_loss_fake: 0.0006, g_loss: 8.2957
Epoch [29/30], Step [203/407], d_loss_real: 0.0011, d_loss_fake: 0.0005, g_loss: 8.4446
Epoch [29/30], Step [406/407], d_loss_real: 0.0008, d_loss_fake: 0.0005, g_loss: 8.4341
Epoch [30/30], Step [203/407], d_loss_real: 0.0005, d_loss_fake: 0.0006, g_loss: 8.2964
Epoch [30/30], Step [406/407], d_loss_real: 0.0005, d_loss_fake: 0.0007, g_loss: 8.1438
Finish training Indian_Pines_Corrected dataset
Save checkpoint to ./experiments/models/checkpoints/GAN/Indian_Pines_Corrected
finish all datasets

Start training Indian_Pines_Corrected dataset
warmup epoches 1/3
Epoch [1/30], Step [203/407], d_loss_real: 0.6642, d_loss_fake: 0.3132
Epoch [1/30], Step [406/407], d_loss_real: 0.5495, d_loss_fake: 0.2431
warmup epoches 2/3
Epoch [2/30], Step [203/407], d_loss_real: 0.3330, d_loss_fake: 0.1153
Epoch [2/30], Step [406/407], d_loss_real: 0.2997, d_loss_fake: 0.1008
warmup epoches 3/3
Epoch [3/30], Step [203/407], d_loss_real: 0.2186, d_loss_fake: 0.0680
Epoch [3/30], Step [406/407], d_loss_real: 0.2006, d_loss_fake: 0.0617
Epoch [4/30], Step [203/407], d_loss_real: 0.1641, d_loss_fake: 0.0999, g_loss: 2.4374
Epoch [4/30], Step [406/407], d_loss_real: 0.1540, d_loss_fake: 0.0901, g_loss: 2.5165
Epoch [5/30], Step [203/407], d_loss_real: 0.1262, d_loss_fake: 0.0624, g_loss: 2.8376
Epoch [5/30], Step [406/407], d_loss_real: 0.1184, d_loss_fake: 0.0583, g_loss: 2.8988
Epoch [6/30], Step [203/407], d_loss_real: 0.0988, d_loss_fake: 0.0456, g_loss: 3.1598
Epoch [6/30], Step [406/407], d_loss_real: 0.0929, d_loss_fake: 0.0435, g_loss: 3.2028
Epoch [7/30], Step [203/407], d_loss_real: 0.0764, d_loss_fake: 0.0396, g_loss: 3.3046
Epoch [7/30], Step [406/407], d_loss_real: 0.0725, d_loss_fake: 0.0373, g_loss: 3.3593
Epoch [8/30], Step [203/407], d_loss_real: 0.0608, d_loss_fake: 0.0286, g_loss: 3.6237
Epoch [8/30], Step [406/407], d_loss_real: 0.0571, d_loss_fake: 0.0244, g_loss: 3.7905
Epoch [9/30], Step [203/407], d_loss_real: 0.0468, d_loss_fake: 0.0185, g_loss: 4.0335
Epoch [9/30], Step [406/407], d_loss_real: 0.0443, d_loss_fake: 0.0184, g_loss: 4.0356
Epoch [10/30], Step [203/407], d_loss_real: 0.0374, d_loss_fake: 0.0161, g_loss: 4.1754
Epoch [10/30], Step [406/407], d_loss_real: 0.0356, d_loss_fake: 0.0158, g_loss: 4.1993
Epoch [11/30], Step [203/407], d_loss_real: 0.0305, d_loss_fake: 0.0155, g_loss: 4.2284
Epoch [11/30], Step [406/407], d_loss_real: 0.0291, d_loss_fake: 0.0138, g_loss: 4.3648
Epoch [12/30], Step [203/407], d_loss_real: 0.0250, d_loss_fake: 0.0091, g_loss: 4.7636
Epoch [12/30], Step [406/407], d_loss_real: 0.0236, d_loss_fake: 0.0092, g_loss: 4.7799
Epoch [13/30], Step [203/407], d_loss_real: 0.0200, d_loss_fake: 0.0084, g_loss: 4.8378
Epoch [13/30], Step [406/407], d_loss_real: 0.0189, d_loss_fake: 0.0080, g_loss: 4.8901
Epoch [14/30], Step [203/407], d_loss_real: 0.0162, d_loss_fake: 0.0079, g_loss: 4.9209
Epoch [14/30], Step [406/407], d_loss_real: 0.0155, d_loss_fake: 0.0071, g_loss: 5.0149
Epoch [15/30], Step [203/407], d_loss_real: 0.0134, d_loss_fake: 0.0064, g_loss: 5.1087
Epoch [15/30], Step [406/407], d_loss_real: 0.0128, d_loss_fake: 0.0059, g_loss: 5.1751
Epoch [16/30], Step [203/407], d_loss_real: 0.0112, d_loss_fake: 0.0051, g_loss: 5.3180
Epoch [16/30], Step [406/407], d_loss_real: 0.0107, d_loss_fake: 0.0048, g_loss: 5.3766
Epoch [17/30], Step [203/407], d_loss_real: 0.0093, d_loss_fake: 0.0045, g_loss: 5.4534
Epoch [17/30], Step [406/407], d_loss_real: 0.0090, d_loss_fake: 0.0042, g_loss: 5.5334
Epoch [18/30], Step [203/407], d_loss_real: 0.0077, d_loss_fake: 0.0028, g_loss: 5.9897
Epoch [18/30], Step [406/407], d_loss_real: 0.0073, d_loss_fake: 0.0026, g_loss: 6.0492
Epoch [19/30], Step [203/407], d_loss_real: 0.0064, d_loss_fake: 0.0023, g_loss: 6.1503
Epoch [19/30], Step [406/407], d_loss_real: 0.0061, d_loss_fake: 0.0021, g_loss: 6.2604
Epoch [20/30], Step [203/407], d_loss_real: 0.0052, d_loss_fake: 0.0017, g_loss: 6.4921
Epoch [20/30], Step [406/407], d_loss_real: 0.0049, d_loss_fake: 0.0017, g_loss: 6.4715
Epoch [21/30], Step [203/407], d_loss_real: 0.0042, d_loss_fake: 0.0011, g_loss: 6.9640
Epoch [21/30], Step [406/407], d_loss_real: 0.0040, d_loss_fake: 0.0011, g_loss: 6.9419
Epoch [22/30], Step [203/407], d_loss_real: 0.0034, d_loss_fake: 0.0014, g_loss: 6.6095
Epoch [22/30], Step [406/407], d_loss_real: 0.0033, d_loss_fake: 0.0014, g_loss: 6.6564
Epoch [23/30], Step [203/407], d_loss_real: 0.0030, d_loss_fake: 0.0013, g_loss: 6.8251
Epoch [23/30], Step [406/407], d_loss_real: 0.0028, d_loss_fake: 0.0014, g_loss: 6.6886
Epoch [24/30], Step [203/407], d_loss_real: 0.0029, d_loss_fake: 0.0012, g_loss: 6.7947
Epoch [24/30], Step [406/407], d_loss_real: 0.0027, d_loss_fake: 0.0010, g_loss: 6.9970
Epoch [25/30], Step [203/407], d_loss_real: 0.0021, d_loss_fake: 0.0007, g_loss: 7.2900
Epoch [25/30], Step [406/407], d_loss_real: 0.0023, d_loss_fake: 0.0007, g_loss: 7.2964
Epoch [26/30], Step [203/407], d_loss_real: 0.0019, d_loss_fake: 0.0011, g_loss: 6.9258
Epoch [26/30], Step [406/407], d_loss_real: 0.0017, d_loss_fake: 0.0011, g_loss: 6.9184
Epoch [27/30], Step [203/407], d_loss_real: 0.0014, d_loss_fake: 0.0008, g_loss: 7.2260
Epoch [27/30], Step [406/407], d_loss_real: 0.0014, d_loss_fake: 0.0007, g_loss: 7.3699
Epoch [28/30], Step [203/407], d_loss_real: 0.0012, d_loss_fake: 0.0005, g_loss: 7.6487
Epoch [28/30], Step [406/407], d_loss_real: 0.0011, d_loss_fake: 0.0005, g_loss: 7.7074
Epoch [29/30], Step [203/407], d_loss_real: 0.0010, d_loss_fake: 0.0004, g_loss: 7.8756
Epoch [29/30], Step [406/407], d_loss_real: 0.0010, d_loss_fake: 0.0004, g_loss: 7.9467
Epoch [30/30], Step [203/407], d_loss_real: 0.0008, d_loss_fake: 0.0003, g_loss: 8.1083
Epoch [30/30], Step [406/407], d_loss_real: 0.0008, d_loss_fake: 0.0003, g_loss: 8.0860
Finish training Indian_Pines_Corrected dataset
Save checkpoint to ./experiments/models/checkpoints/GAN/Indian_Pines_Corrected
finish all datasets

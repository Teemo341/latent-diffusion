Start training PaviaU dataset
Epoch 1, MSE Loss: 22681.4573, KL Loss: 71.7873
Epoch 2, MSE Loss: 11949.3764, KL Loss: 88.8282
Epoch 3, MSE Loss: 7733.1083, KL Loss: 87.6782
Epoch 4, MSE Loss: 6205.9057, KL Loss: 85.4637
Epoch 5, MSE Loss: 5731.9043, KL Loss: 82.4502
Epoch 6, MSE Loss: 5539.2400, KL Loss: 80.3485
Epoch 7, MSE Loss: 5448.4261, KL Loss: 78.9671
Epoch 8, MSE Loss: 5362.9400, KL Loss: 78.1546
Epoch 9, MSE Loss: 5320.7433, KL Loss: 77.3323
Epoch 10, MSE Loss: 5279.6694, KL Loss: 76.8727
Epoch 11, MSE Loss: 5248.7581, KL Loss: 76.3834
Epoch 12, MSE Loss: 5226.0537, KL Loss: 76.0975
Epoch 13, MSE Loss: 5226.0998, KL Loss: 75.6979
Epoch 14, MSE Loss: 5185.5649, KL Loss: 75.6781
Epoch 15, MSE Loss: 5163.1689, KL Loss: 75.6113
Epoch 16, MSE Loss: 5147.8534, KL Loss: 75.4604
Epoch 17, MSE Loss: 5139.3391, KL Loss: 75.2521
Epoch 18, MSE Loss: 5112.1867, KL Loss: 75.3082
Epoch 19, MSE Loss: 5099.2128, KL Loss: 75.3035
Epoch 20, MSE Loss: 5088.7323, KL Loss: 75.2437
Epoch 21, MSE Loss: 5079.0384, KL Loss: 75.2195
Epoch 22, MSE Loss: 5067.3530, KL Loss: 75.2188
Epoch 23, MSE Loss: 5055.3143, KL Loss: 75.1808
Epoch 24, MSE Loss: 5050.5999, KL Loss: 75.2245
Epoch 25, MSE Loss: 5039.8958, KL Loss: 75.0922
Epoch 26, MSE Loss: 5032.5606, KL Loss: 75.0590
Epoch 27, MSE Loss: 5021.6819, KL Loss: 75.1200
Epoch 28, MSE Loss: 5010.5115, KL Loss: 75.0697
Epoch 29, MSE Loss: 5011.8586, KL Loss: 75.0467
Epoch 30, MSE Loss: 5003.5645, KL Loss: 75.0507
Epoch 31, MSE Loss: 4997.1709, KL Loss: 75.0846
Epoch 32, MSE Loss: 5000.3362, KL Loss: 75.0928
Epoch 33, MSE Loss: 4988.8193, KL Loss: 75.0729
Epoch 34, MSE Loss: 4979.6300, KL Loss: 75.1619
Epoch 35, MSE Loss: 4969.4190, KL Loss: 75.1565
Epoch 36, MSE Loss: 4974.9091, KL Loss: 75.1244
Epoch 37, MSE Loss: 4963.1202, KL Loss: 75.1057
Epoch 38, MSE Loss: 4956.5206, KL Loss: 75.0770
Epoch 39, MSE Loss: 4960.6705, KL Loss: 75.0524
Epoch 40, MSE Loss: 4953.0614, KL Loss: 75.1232
Epoch 41, MSE Loss: 4946.7404, KL Loss: 75.1735
Epoch 42, MSE Loss: 4944.8555, KL Loss: 75.1701
Epoch 43, MSE Loss: 4939.3804, KL Loss: 75.1837
Epoch 44, MSE Loss: 4939.3346, KL Loss: 75.1980
Epoch 45, MSE Loss: 4932.1852, KL Loss: 75.2338
Epoch 46, MSE Loss: 4930.8176, KL Loss: 75.1653
Epoch 47, MSE Loss: 4930.1568, KL Loss: 75.2176
Epoch 48, MSE Loss: 4927.3400, KL Loss: 75.1756
Epoch 49, MSE Loss: 4930.4803, KL Loss: 75.2149
Epoch 50, MSE Loss: 4924.3096, KL Loss: 75.2121
Epoch 51, MSE Loss: 4920.4073, KL Loss: 75.2372
Epoch 52, MSE Loss: 4919.3795, KL Loss: 75.2006
Epoch 53, MSE Loss: 4918.9244, KL Loss: 75.2702
Epoch 54, MSE Loss: 4914.7499, KL Loss: 75.2522
Epoch 55, MSE Loss: 4915.0340, KL Loss: 75.2986
Epoch 56, MSE Loss: 4910.3233, KL Loss: 75.2928
Epoch 57, MSE Loss: 4913.1118, KL Loss: 75.2918
Epoch 58, MSE Loss: 4909.6895, KL Loss: 75.2664
Epoch 59, MSE Loss: 4905.2776, KL Loss: 75.2696
Epoch 60, MSE Loss: 4906.3483, KL Loss: 75.2231
Epoch 61, MSE Loss: 4907.3864, KL Loss: 75.2857
Epoch 62, MSE Loss: 4904.8544, KL Loss: 75.2947
Epoch 63, MSE Loss: 4904.2436, KL Loss: 75.3468
Epoch 64, MSE Loss: 4905.0872, KL Loss: 75.3297
Epoch 65, MSE Loss: 4904.4646, KL Loss: 75.3497
Epoch 66, MSE Loss: 4900.2837, KL Loss: 75.3167
Epoch 67, MSE Loss: 4898.1344, KL Loss: 75.3388
Epoch 68, MSE Loss: 4897.2105, KL Loss: 75.4064
Epoch 69, MSE Loss: 4897.1150, KL Loss: 75.3967
Epoch 70, MSE Loss: 4898.0691, KL Loss: 75.3828
Epoch 71, MSE Loss: 4894.6673, KL Loss: 75.3481
Epoch 72, MSE Loss: 4896.5686, KL Loss: 75.3907
Epoch 73, MSE Loss: 4894.3595, KL Loss: 75.4038
Epoch 74, MSE Loss: 4894.7790, KL Loss: 75.3757
Epoch 75, MSE Loss: 4893.7542, KL Loss: 75.4087
Epoch 76, MSE Loss: 4890.5153, KL Loss: 75.4346
Epoch 77, MSE Loss: 4891.6993, KL Loss: 75.4457
Epoch 78, MSE Loss: 4892.1677, KL Loss: 75.3839
Epoch 79, MSE Loss: 4892.9264, KL Loss: 75.4463
Epoch 80, MSE Loss: 4890.7943, KL Loss: 75.3531
Epoch 81, MSE Loss: 4893.3934, KL Loss: 75.3654
Epoch 82, MSE Loss: 4886.7888, KL Loss: 75.3897
Epoch 83, MSE Loss: 4890.7759, KL Loss: 75.4910
Epoch 84, MSE Loss: 4886.6524, KL Loss: 75.4256
Epoch 85, MSE Loss: 4886.5814, KL Loss: 75.4182
Epoch 86, MSE Loss: 4889.3250, KL Loss: 75.4111
Epoch 87, MSE Loss: 4888.5293, KL Loss: 75.3941
Epoch 88, MSE Loss: 4888.4330, KL Loss: 75.4018
Epoch 89, MSE Loss: 4889.6703, KL Loss: 75.4595
Epoch 90, MSE Loss: 4887.2450, KL Loss: 75.4184
Epoch 91, MSE Loss: 4888.7886, KL Loss: 75.3509
Epoch 92, MSE Loss: 4888.8562, KL Loss: 75.3886
Epoch 93, MSE Loss: 4886.3391, KL Loss: 75.4046
Epoch 94, MSE Loss: 4886.3273, KL Loss: 75.4460
Epoch 95, MSE Loss: 4885.5402, KL Loss: 75.4279
Epoch 96, MSE Loss: 4883.2428, KL Loss: 75.4588
Epoch 97, MSE Loss: 4883.7084, KL Loss: 75.4635
Epoch 98, MSE Loss: 4885.3456, KL Loss: 75.4183
Epoch 99, MSE Loss: 4885.7512, KL Loss: 75.4323
Epoch 100, MSE Loss: 4882.0393, KL Loss: 75.4084
Finish training PaviaU dataset
Save checkpoint to ./experiments/models/checkpoints/VAE/PaviaU
finish all datasets

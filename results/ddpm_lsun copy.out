True
2
Global seed set to 23
Running on GPUs 0,1
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 294.97 M params.
Keeping EMAs of 522.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/first_stage_models/kl-f8/model.ckpt
Training LatentDiffusion as an unconditional model.
Monitoring val/loss_simple_ema as checkpoint metric.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2023-06-23T17-51-59_lsun_churches-ldm-kl-8/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 3}}
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
#### Data #####
train, LSUNChurchesTrain, 121227
validation, LSUNChurchesValidation, 5000
accumulate_grad_batches = 1
Setting learning rate to 9.60e-03 = 1 (accumulate_grad_batches) * 2 (num_gpus) * 96 (batchsize) * 5.00e-05 (base_lr)
Global seed set to 23
Global seed set to 23
initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2
Global seed set to 23
initializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All DDP processes registered. Starting ddp with 2 processes
----------------------------------------------------------------------------------------------------

/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.
  rank_zero_deprecation(
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Setting up LambdaLR scheduler...
Set SLURM handle signals.
Set SLURM handle signals.
Project config
model:
  base_learning_rate: 5.0e-05
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    linear_start: 0.0015
    linear_end: 0.0155
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    loss_type: l1
    first_stage_key: image
    cond_stage_key: image
    image_size: 32
    channels: 4
    cond_stage_trainable: false
    concat_mode: false
    scale_by_std: true
    monitor: val/loss_simple_ema
    scheduler_config:
      target: ldm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps:
        - 10000
        cycle_lengths:
        - 10000000000000
        f_start:
        - 1.0e-06
        f_max:
        - 1.0
        f_min:
        - 1.0
    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 32
        in_channels: 4
        out_channels: 4
        model_channels: 192
        attention_resolutions:
        - 1
        - 2
        - 4
        - 8
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 2
        - 4
        - 4
        num_heads: 8
        use_scale_shift_norm: true
        resblock_updown: true
    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ckpt_path: models/first_stage_models/kl-f8/model.ckpt
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    cond_stage_config: __is_unconditional__
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 96
    num_workers: 5
    wrap: false
    train:
      target: ldm.data.lsun.LSUNChurchesTrain
      params:
        size: 256
    validation:
      target: ldm.data.lsun.LSUNChurchesValidation
      params:
        size: 256

Lightning config
callbacks:
  image_logger:
    target: main.ImageLogger
    params:
      batch_frequency: 5000
      max_images: 8
      increase_log_steps: false
trainer:
  benchmark: true
  accelerator: ddp
  gpus: 0,1


  | Name              | Type             | Params
-------------------------------------------------------
0 | model             | DiffusionWrapper | 294 M 
1 | model_ema         | LitEma           | 0     
2 | first_stage_model | AutoencoderKL    | 83.7 M
-------------------------------------------------------
294 M     Trainable params
83.7 M    Non-trainable params
378 M     Total params
1,514.483 Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]True
2
Running on GPUs 0,1
LatentDiffusion: Running in eps-prediction mode
DiffusionWrapper has 294.97 M params.
Keeping EMAs of 522.
making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from models/first_stage_models/kl-f8/model.ckpt
Training LatentDiffusion as an unconditional model.
Monitoring val/loss_simple_ema as checkpoint metric.
Merged modelckpt-cfg: 
{'target': 'pytorch_lightning.callbacks.ModelCheckpoint', 'params': {'dirpath': 'logs/2023-06-23T17-52-07_lsun_churches-ldm-kl-8/checkpoints', 'filename': '{epoch:06}', 'verbose': True, 'save_last': True, 'monitor': 'val/loss_simple_ema', 'save_top_k': 3}}
#### Data #####
train, LSUNChurchesTrain, 121227
validation, LSUNChurchesValidation, 5000
accumulate_grad_batches = 1
Setting learning rate to 9.60e-03 = 1 (accumulate_grad_batches) * 2 (num_gpus) * 96 (batchsize) * 5.00e-05 (base_lr)
Setting up LambdaLR scheduler...
Summoning checkpoint.
Traceback (most recent call last):
  File "/home/home_node6_1/ssy1/latent-diffusion/main.py", line 722, in <module>
    trainer.fit(model, data)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
    self._run(model)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 918, in _run
    self._dispatch()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
    self.accelerator.start_training(self)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 92, in start_training
    self.training_type_plugin.start_training(trainer)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 161, in start_training
    self._results = trainer.run_stage()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 996, in run_stage
    return self._run_train()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1031, in _run_train
    self._run_sanity_check(self.lightning_module)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1115, in _run_sanity_check
    self._evaluation_loop.run()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 110, in advance
    dl_outputs = self.epoch_loop.run(
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 110, in advance
    output = self.evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 154, in evaluation_step
    output = self.trainer.accelerator.validation_step(step_kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 211, in validation_step
    return self.training_type_plugin.validation_step(*step_kwargs.values())
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py", line 386, in validation_step
    return self.model(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/overrides/base.py", line 93, in forward
    output = self.module.validation_step(*inputs, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 359, in validation_step
    _, loss_dict_no_ema = self.shared_step(batch)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 867, in shared_step
    loss = self(x, c)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 879, in forward
    return self.p_losses(x, c, t, *args, **kwargs)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 1030, in p_losses
    logvar_t = self.logvar[t].to(self.device)
RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)

Traceback (most recent call last):
  File "main.py", line 722, in <module>
    trainer.fit(model, data)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
    self._run(model)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 918, in _run
    self._dispatch()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
    self.accelerator.start_training(self)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 92, in start_training
    self.training_type_plugin.start_training(trainer)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 161, in start_training
    self._results = trainer.run_stage()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 996, in run_stage
    return self._run_train()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1031, in _run_train
    self._run_sanity_check(self.lightning_module)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1115, in _run_sanity_check
    self._evaluation_loop.run()
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 110, in advance
    dl_outputs = self.epoch_loop.run(
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
    self.advance(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 110, in advance
    output = self.evaluation_step(batch, batch_idx, dataloader_idx)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 154, in evaluation_step
    output = self.trainer.accelerator.validation_step(step_kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 211, in validation_step
    return self.training_type_plugin.validation_step(*step_kwargs.values())
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/ddp.py", line 386, in validation_step
    return self.model(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/overrides/base.py", line 93, in forward
    output = self.module.validation_step(*inputs, **kwargs)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 359, in validation_step
    _, loss_dict_no_ema = self.shared_step(batch)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 867, in shared_step
    loss = self(x, c)
  File "/home/home_node6_1/ssy1/anaconda3/envs/ldm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 879, in forward
    return self.p_losses(x, c, t, *args, **kwargs)
  File "/home/home_node6_1/ssy1/latent-diffusion/ldm/models/diffusion/ddpm.py", line 1030, in p_losses
    logvar_t = self.logvar[t].to(self.device)
RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)

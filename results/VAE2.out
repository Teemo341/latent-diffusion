Start training Pavia dataset
Epoch 1, MSE Loss: 14878.9795, KL Loss: 85.4981
Epoch 2, MSE Loss: 5562.4448, KL Loss: 81.1240
Epoch 3, MSE Loss: 5353.8180, KL Loss: 77.3473
Epoch 4, MSE Loss: 5296.3638, KL Loss: 75.7475
Epoch 5, MSE Loss: 5235.0273, KL Loss: 75.3586
Epoch 6, MSE Loss: 5148.6532, KL Loss: 75.1113
Epoch 7, MSE Loss: 5103.4730, KL Loss: 74.7793
Epoch 8, MSE Loss: 5065.7337, KL Loss: 74.5353
Epoch 9, MSE Loss: 5033.2848, KL Loss: 74.4939
Epoch 10, MSE Loss: 5008.3811, KL Loss: 74.3541
Epoch 11, MSE Loss: 4988.7360, KL Loss: 74.3470
Epoch 12, MSE Loss: 4968.3769, KL Loss: 74.2882
Epoch 13, MSE Loss: 4948.7861, KL Loss: 74.2311
Epoch 14, MSE Loss: 4944.1604, KL Loss: 74.2103
Epoch 15, MSE Loss: 4921.4628, KL Loss: 74.2281
Epoch 16, MSE Loss: 4902.5973, KL Loss: 74.2635
Epoch 17, MSE Loss: 4912.6023, KL Loss: 74.1492
Epoch 18, MSE Loss: 4887.6790, KL Loss: 74.2844
Epoch 19, MSE Loss: 4874.6581, KL Loss: 74.2994
Epoch 20, MSE Loss: 4863.2079, KL Loss: 74.3287
Epoch 21, MSE Loss: 4855.0285, KL Loss: 74.3598
Epoch 22, MSE Loss: 4848.0202, KL Loss: 74.3232
Epoch 23, MSE Loss: 4841.6893, KL Loss: 74.4435
Epoch 24, MSE Loss: 4832.6820, KL Loss: 74.4455
Epoch 25, MSE Loss: 4826.6352, KL Loss: 74.4860
Epoch 26, MSE Loss: 4845.3546, KL Loss: 74.4951
Epoch 27, MSE Loss: 4818.6154, KL Loss: 74.5728
Epoch 28, MSE Loss: 4812.9813, KL Loss: 74.5504
Epoch 29, MSE Loss: 4805.4921, KL Loss: 74.6732
Epoch 30, MSE Loss: 4802.2339, KL Loss: 74.6985
Epoch 31, MSE Loss: 4797.1227, KL Loss: 74.6935
Epoch 32, MSE Loss: 4792.8921, KL Loss: 74.7613
Epoch 33, MSE Loss: 4788.0872, KL Loss: 74.8033
Epoch 34, MSE Loss: 4785.8861, KL Loss: 74.8081
Epoch 35, MSE Loss: 4781.0672, KL Loss: 74.8504
Epoch 36, MSE Loss: 4778.0940, KL Loss: 74.8566
Epoch 37, MSE Loss: 4775.5735, KL Loss: 74.9304
Epoch 38, MSE Loss: 4774.2955, KL Loss: 74.9335
Epoch 39, MSE Loss: 4769.6918, KL Loss: 74.9603
Epoch 40, MSE Loss: 4766.2949, KL Loss: 74.9898
Epoch 41, MSE Loss: 4765.0279, KL Loss: 74.9790
Epoch 42, MSE Loss: 4762.8359, KL Loss: 75.0128
Epoch 43, MSE Loss: 4760.6393, KL Loss: 75.0721
Epoch 44, MSE Loss: 4759.4303, KL Loss: 75.0803
Epoch 45, MSE Loss: 4760.1743, KL Loss: 75.0765
Epoch 46, MSE Loss: 4754.4783, KL Loss: 75.0824
Epoch 47, MSE Loss: 4753.9974, KL Loss: 75.1376
Epoch 48, MSE Loss: 4751.0469, KL Loss: 75.1530
Epoch 49, MSE Loss: 4749.7677, KL Loss: 75.1758
Epoch 50, MSE Loss: 4747.5980, KL Loss: 75.2134
Epoch 51, MSE Loss: 4746.4515, KL Loss: 75.2123
Epoch 52, MSE Loss: 4745.7331, KL Loss: 75.2356
Epoch 53, MSE Loss: 4743.3597, KL Loss: 75.2364
Epoch 54, MSE Loss: 4744.0778, KL Loss: 75.2596
Epoch 55, MSE Loss: 4740.7733, KL Loss: 75.2904
Epoch 56, MSE Loss: 4740.5685, KL Loss: 75.2958
Epoch 57, MSE Loss: 4738.1730, KL Loss: 75.2939
Epoch 58, MSE Loss: 4738.5864, KL Loss: 75.3339
Epoch 59, MSE Loss: 4736.1548, KL Loss: 75.3128
Epoch 60, MSE Loss: 4738.5575, KL Loss: 75.3089
Epoch 61, MSE Loss: 4735.9368, KL Loss: 75.3814
Epoch 62, MSE Loss: 4736.2777, KL Loss: 75.3925
Epoch 63, MSE Loss: 4733.7671, KL Loss: 75.3731
Epoch 64, MSE Loss: 4732.0271, KL Loss: 75.4330
Epoch 65, MSE Loss: 4733.7481, KL Loss: 75.4046
Epoch 66, MSE Loss: 4730.8346, KL Loss: 75.4275
Epoch 67, MSE Loss: 4731.7584, KL Loss: 75.4071
Epoch 68, MSE Loss: 4728.9258, KL Loss: 75.4244
Epoch 69, MSE Loss: 4730.1739, KL Loss: 75.4450
Epoch 70, MSE Loss: 4727.7808, KL Loss: 75.4727
Epoch 71, MSE Loss: 4728.8825, KL Loss: 75.4712
Epoch 72, MSE Loss: 4730.7942, KL Loss: 75.4776
Epoch 73, MSE Loss: 4728.9654, KL Loss: 75.4693
Epoch 74, MSE Loss: 4726.9157, KL Loss: 75.4783
Epoch 75, MSE Loss: 4728.0831, KL Loss: 75.4811
Epoch 76, MSE Loss: 4727.4826, KL Loss: 75.5136
Epoch 77, MSE Loss: 4726.9917, KL Loss: 75.5108
Epoch 78, MSE Loss: 4726.3830, KL Loss: 75.4865
Epoch 79, MSE Loss: 4725.0652, KL Loss: 75.5050
Epoch 80, MSE Loss: 4723.3657, KL Loss: 75.5081
Epoch 81, MSE Loss: 4725.3818, KL Loss: 75.5319
Epoch 82, MSE Loss: 4724.8537, KL Loss: 75.5092
Epoch 83, MSE Loss: 4724.6654, KL Loss: 75.5109
Epoch 84, MSE Loss: 4725.8544, KL Loss: 75.5305
Epoch 85, MSE Loss: 4724.1157, KL Loss: 75.5423
Epoch 86, MSE Loss: 4723.5554, KL Loss: 75.5179
Epoch 87, MSE Loss: 4724.3030, KL Loss: 75.5255
Epoch 88, MSE Loss: 4723.8634, KL Loss: 75.5450
Epoch 89, MSE Loss: 4723.2207, KL Loss: 75.5537
Epoch 90, MSE Loss: 4723.2294, KL Loss: 75.5380
Epoch 91, MSE Loss: 4722.7870, KL Loss: 75.5325
Epoch 92, MSE Loss: 4722.6883, KL Loss: 75.5715
Epoch 93, MSE Loss: 4723.1495, KL Loss: 75.5264
Epoch 94, MSE Loss: 4723.8029, KL Loss: 75.5638
Epoch 95, MSE Loss: 4723.4441, KL Loss: 75.5667
Epoch 96, MSE Loss: 4721.5638, KL Loss: 75.5640
Epoch 97, MSE Loss: 4721.8871, KL Loss: 75.5879
Epoch 98, MSE Loss: 4722.5766, KL Loss: 75.5790
Epoch 99, MSE Loss: 4722.1605, KL Loss: 75.5960
Epoch 100, MSE Loss: 4721.0222, KL Loss: 75.5542
Finish training Pavia dataset
Save checkpoint to ./experiments/models/checkpoints/VAE/Pavia
finish all datasets
